{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fc6eebe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "from transformers import BertTokenizer\n",
    "import torch\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dc758aae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           movie_name  year_x          actor_name  character_name  year_y  \\\n",
      "0  Sufi Paranja Katha    2010  Sharbani Mukherjee  Karthi, Suhara    2010   \n",
      "1  Sufi Paranja Katha    2010       Thampi Antony     Sanku Menon    2010   \n",
      "2  Sufi Paranja Katha    2010        Prakash Bare        Mamootty    2010   \n",
      "3  Sufi Paranja Katha    2010   Jagathy Sreekumar  Avaru Musaliar    2010   \n",
      "4  Sufi Paranja Katha    2010     V. K. Sreeraman    Saidu Mullah    2010   \n",
      "\n",
      "                                                plot  \n",
      "0  This film is a narrative by Sufi, a Muslim sch...  \n",
      "1  This film is a narrative by Sufi, a Muslim sch...  \n",
      "2  This film is a narrative by Sufi, a Muslim sch...  \n",
      "3  This film is a narrative by Sufi, a Muslim sch...  \n",
      "4  This film is a narrative by Sufi, a Muslim sch...  \n"
     ]
    }
   ],
   "source": [
    "roles_df = pd.read_csv(\"roles_clean.csv\")\n",
    "movies_df = pd.read_csv(\"movies_clean.csv\")\n",
    "\n",
    "df = roles_df.merge(movies_df, on=\"movie_name\", how=\"inner\")\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5698a4eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|██████████| 103/103 [00:00<00:00, 839.23it/s, Materializing param=pooler.dense.weight]                             \n",
      "\u001b[1mBertModel LOAD REPORT\u001b[0m from: sentence-transformers/all-MiniLM-L6-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n",
      "Batches: 100%|██████████| 291/291 [03:15<00:00,  1.49it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['sbert_model.pkl']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"input_text\"] = df[\"plot\"] + \" \" + df[\"character_name\"]\n",
    "\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "embeddings = model.encode(df[\"input_text\"].tolist(), show_progress_bar=True)\n",
    "\n",
    "np.save(\"plot_embeddings.npy\", embeddings)\n",
    "df.to_csv(\"final_dataset_with_text.csv\", index=False)\n",
    "\n",
    "joblib.dump(model, \"sbert_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fb7715d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|██████████| 103/103 [00:00<00:00, 411.63it/s, Materializing param=pooler.dense.weight]                             \n",
      "\u001b[1mBertModel LOAD REPORT\u001b[0m from: sentence-transformers/all-MiniLM-L6-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "df = pd.read_csv(\"final_dataset_with_text.csv\")\n",
    "embeddings = np.load(\"plot_embeddings.npy\")\n",
    "\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "def suggest_actors(user_plot, top_k=5):\n",
    "    query = model.encode([user_plot])\n",
    "    scores = cosine_similarity(query, embeddings)[0]\n",
    "\n",
    "    top_idx = scores.argsort()[-top_k:][::-1]\n",
    "\n",
    "    return df.iloc[top_idx][[\"actor_name\", \"movie_name\", \"character_name\"]]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "castnet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
