{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fc6eebe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "from transformers import BertTokenizer\n",
    "import torch\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dc758aae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           movie_name  year          actor_name  character_name  \\\n",
      "0  sufi paranja katha  2010  Sharbani Mukherjee  Karthi, Suhara   \n",
      "1  sufi paranja katha  2010       Thampi Antony     Sanku Menon   \n",
      "2  sufi paranja katha  2010        Prakash Bare        Mamootty   \n",
      "3  sufi paranja katha  2010   Jagathy Sreekumar  Avaru Musaliar   \n",
      "4  sufi paranja katha  2010     V. K. Sreeraman    Saidu Mullah   \n",
      "\n",
      "                                                plot  \n",
      "0  This film is a narrative by Sufi, a Muslim sch...  \n",
      "1  This film is a narrative by Sufi, a Muslim sch...  \n",
      "2  This film is a narrative by Sufi, a Muslim sch...  \n",
      "3  This film is a narrative by Sufi, a Muslim sch...  \n",
      "4  This film is a narrative by Sufi, a Muslim sch...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load source files\n",
    "movies_df = pd.read_csv(\"movies_with_plot.csv\")\n",
    "roles_df = pd.read_csv(\"malayalam_movie_cast_dataset.csv\")\n",
    "\n",
    "# Normalize movie names\n",
    "movies_df[\"movie_name\"] = movies_df[\"movie_name\"].str.strip().str.lower()\n",
    "roles_df[\"movie_name\"] = roles_df[\"movie_name\"].str.strip().str.lower()\n",
    "\n",
    "# Merge dynamically\n",
    "df = pd.merge(\n",
    "    roles_df,\n",
    "    movies_df,\n",
    "    on=[\"movie_name\", \"year\"],\n",
    "    how=\"inner\"\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5698a4eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|██████████| 103/103 [00:00<00:00, 742.03it/s, Materializing param=pooler.dense.weight]                             \n",
      "\u001b[1mBertModel LOAD REPORT\u001b[0m from: all-MiniLM-L6-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n",
      "Batches: 100%|██████████| 291/291 [03:37<00:00,  1.34it/s]\n"
     ]
    }
   ],
   "source": [
    "# 1. Build input text\n",
    "df[\"input_text\"] = df[\"plot\"] + \" Character: \" + df[\"character_name\"]\n",
    "\n",
    "\n",
    "# 2. Embed\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "train_embeddings = model.encode(df[\"input_text\"].tolist(), show_progress_bar=True)\n",
    "\n",
    "# 3. Save\n",
    "np.save(\"final_embeddings.npy\", train_embeddings)\n",
    "df.to_csv(\"train_data.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fb7715d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def suggest_actors(user_plot, user_character, top_k=5):\n",
    "    query_text = user_plot + \" Character: \" + user_character\n",
    "    query_emb = model.encode([query_text])\n",
    "\n",
    "    sims = cosine_similarity(query_emb, train_embeddings)[0]\n",
    "    top_idx = np.argsort(sims)[-top_k:][::-1]\n",
    "\n",
    "    return train_df.iloc[top_idx][[\"actor_name\", \"movie_name\", \"character_name\"]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "castnet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
