{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebedd30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import nltk\n",
    "import wikipedia\n",
    "from lxml import html\n",
    "import os\n",
    "import re\n",
    "import getpass\n",
    "from google import genai\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0\"\n",
    "}\n",
    "BASE_URL = \"https://en.wikipedia.org/wiki/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35050576",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_wikipedia(movie_name,year):\n",
    "    search_url = \"https://en.wikipedia.org/w/api.php\"\n",
    "    params = {\n",
    "        \"action\": \"query\",\n",
    "        \"list\": \"search\",\n",
    "        \"srsearch\": f\"{movie_name}  {year}\",\n",
    "        \"format\": \"json\"\n",
    "    }\n",
    "\n",
    "    r = requests.get(search_url, params=params, headers=headers,timeout=20)\n",
    "    data = r.json()\n",
    "    if data[\"query\"][\"search\"]:\n",
    "        return data[\"query\"][\"search\"][0][\"pageid\"]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# Get plot from page\n",
    "# --------------------------\n",
    "def get_plot_from_pageid(pageid):\n",
    "    if pageid !=  None:\n",
    "        try:\n",
    "            page = wikipedia.WikipediaPage(pageid=pageid)\n",
    "            text = page.section(section_title=\"Plot\")\n",
    "            return text\n",
    "        except wikipedia.DisambiguationError as e:\n",
    "            print(\"error occured\",e)\n",
    "            return \"\"\n",
    "    else:\n",
    "        print(\"No page exists for pageid\",pageid)\n",
    "        return \"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "820b88ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Done\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "\n",
    "df_cast = pd.read_csv(\"malayalam_movie_cast_dataset.csv\")\n",
    "df_movies = df_cast[[\"movie_name\", \"year\"]].drop_duplicates()\n",
    "\n",
    "output_file = \"movies_with_plot.csv\"\n",
    "\n",
    "if not os.path.exists(output_file):\n",
    "    pd.DataFrame(columns=[\"movie_name\", \"year\", \"plot\"]).to_csv(output_file, index=False)\n",
    "\n",
    "done = set(pd.read_csv(output_file)[\"movie_name\"])\n",
    "\n",
    "for _, row in df_movies.iterrows():\n",
    "    movie = row[\"movie_name\"]\n",
    "    year = row[\"year\"]\n",
    "\n",
    "    if movie in done:\n",
    "        continue\n",
    "\n",
    "    print(f\"Processing: {movie}\")\n",
    "\n",
    "    try:\n",
    "        page_id = search_wikipedia(movie, year)   # must use timeout inside\n",
    "        plot = get_plot_from_pageid(page_id)      # must use timeout inside\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Skipping\", movie, \"due to\", e)\n",
    "        plot = \"\"\n",
    "\n",
    "    pd.DataFrame([{\n",
    "        \"movie_name\": movie,\n",
    "        \"year\": year,\n",
    "        \"plot\": plot\n",
    "    }]).to_csv(output_file, mode=\"a\", header=False, index=False)\n",
    "\n",
    "    time.sleep(1)\n",
    "\n",
    "print(\"✅ Done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61e5f4b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total movies with empty plots: 0 among 597\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"movies_with_plot.csv\")\n",
    "\n",
    "# keep plot column\n",
    "df = df[[\"movie_name\", \"year\", \"plot\"]].drop_duplicates()\n",
    "\n",
    "empty_count = 0\n",
    "total = 0\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    total += 1\n",
    "    plot = str(row[\"plot\"]).strip()   # convert NaN to string and strip spaces\n",
    "\n",
    "    if len(plot) < 5:\n",
    "        empty_count += 1\n",
    "        # print(\"Empty plot:\", row[\"movie_name\"])\n",
    "\n",
    "print(\"Total movies with empty plots:\", empty_count, \"among\", total)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3ee9965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ CSV updated with missing plots\n"
     ]
    }
   ],
   "source": [
    "# searching for remaining plots via OMDb API\n",
    "OMDB_KEY = os.getenv(\"OMDB_KEY\")\n",
    "def get_plot_from_OMDb(movie,year):\n",
    "    params = {\n",
    "        \"apikey\": OMDB_KEY,\n",
    "        \"t\": movie,      # use title, not search\n",
    "        \"y\": year,\n",
    "        \"plot\": \"full\"\n",
    "    }\n",
    "    r = requests.get(\"http://www.omdbapi.com/\", params=params, timeout=20)\n",
    "    data = r.json()\n",
    "    # debug (optional)\n",
    "    # print(data)\n",
    "    if data.get(\"Response\") == \"True\":\n",
    "        return data.get(\"Plot\", \"\")\n",
    "    else:\n",
    "        print(\"Not found:\", movie, data.get(\"Error\"))\n",
    "        return \"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"movies_with_plot.csv\")\n",
    "df[\"plot\"] = df[\"plot\"].fillna(\"\")\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "\n",
    "    if row[\"plot\"].strip() != \"\":\n",
    "        continue\n",
    "\n",
    "    movie = row[\"movie_name\"]\n",
    "    year = row[\"year\"]\n",
    "\n",
    "    print(f\"Fetching plot for: {movie} ({year})\")\n",
    "\n",
    "    try:\n",
    "        plot = get_plot_from_OMDb(movie, year)\n",
    "    except Exception as e:\n",
    "        print(\"Error for\", movie, \":\", e)\n",
    "        plot = \"\"\n",
    "\n",
    "    df.at[i, \"plot\"] = plot\n",
    "    df.to_csv(\"movies_with_plot.csv\", index=False)\n",
    "\n",
    "    time.sleep(1)\n",
    "\n",
    "print(\"✅ CSV updated with missing plots\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3120a6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ CSV sorted by year\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"movies_with_plot.csv\")\n",
    "\n",
    "df = df.sort_values(by=\"year\")\n",
    "\n",
    "df.to_csv(\"movies_with_plot.csv\", index=False)\n",
    "\n",
    "print(\"✅ CSV sorted by year\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21c91b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Kept only unique movie-year combinations\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv(\"movies_with_plot.csv\")\n",
    "\n",
    "df = df.drop_duplicates(subset=[\"movie_name\", \"year\"])\n",
    "\n",
    "df.to_csv(\"movies_with_plot.csv\", index=False)\n",
    "\n",
    "print(\"✅ Kept only unique movie-year combinations\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ca69479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning done:\n",
      "Movies with plot: 597\n",
      "Roles after filtering: 9297\n"
     ]
    }
   ],
   "source": [
    "#cleaning data by removing empty movies\n",
    "import pandas as pd\n",
    "\n",
    "# Load both files\n",
    "movies_df = pd.read_csv(\"movies_with_plot.csv\")        # movie_name, plot\n",
    "roles_df = pd.read_csv(\"malayalam_movie_cast_dataset.csv\")          # movie_name, character_name, actor_name\n",
    "\n",
    "# 1. Keep only movies that have valid plot\n",
    "movies_df[\"plot\"] = movies_df[\"plot\"].fillna(\"\").str.strip()\n",
    "movies_with_plot = movies_df[movies_df[\"plot\"].str.len() > 50]\n",
    "\n",
    "# 2. Get list of valid movie names\n",
    "valid_movies = set(movies_with_plot[\"movie_name\"])\n",
    "\n",
    "# 3. Filter roles file using valid movies\n",
    "roles_clean = roles_df[roles_df[\"movie_name\"].isin(valid_movies)]\n",
    "\n",
    "# 4. Save cleaned files\n",
    "movies_with_plot.to_csv(\"movies_with_plot.csv\", index=False)\n",
    "roles_clean.to_csv(\"malayalam_movie_cast_dataset.csv\", index=False)\n",
    "\n",
    "print(\"Cleaning done:\")\n",
    "print(\"Movies with plot:\", len(movies_with_plot))\n",
    "print(\"Roles after filtering:\", len(roles_clean))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142f7f78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "castnet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
